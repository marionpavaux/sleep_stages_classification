{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9566bf8c",
   "metadata": {},
   "source": [
    "Marion Pavaux & Anaïs Halimi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23259d8d",
   "metadata": {},
   "source": [
    "# Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f23db7",
   "metadata": {},
   "source": [
    "Sleep disorders are conditions that disturb normal sleep patterns and affect a lot of people. Insomnia, sleep apnea, restless leg syndrome and circadian rhythms disorders are some examples of sleep disorders. According to statistics of the American Sleep Association, 50 to 70% of the US population is suffering from sleep disorders. In France (according to the Fondation pour la Recherche sur le Cerveau) almost 10% of the French population suffers from insomnia. Primary insomnia means this sleep problem is linked to stress or environmental parameters, and may be linked to genetical predispositions, whereas secondary insomnia is linked to a health condition, for instance depression and hyperthyroidism.  \n",
    "Normal sleep is a restorative state. However, when sleep is disrupted or inadequate, it can lead to increased tension, vigilance, and irritability. As sleep disorders have a huge impact on the population, sleep studies improvement is current affair.\n",
    "\n",
    "The sleep cycle contains different stages. In the first place, N1, N2, N3 stages are included in non-REM (non-rapid eye movement) sleep. Finally, there is the REM stage (rapid eye movement), which corresponds to the paradoxal state and dreams.\n",
    "\n",
    "The most used way to study sleep is polysomnography, which refers to a systematic process used to collect physiologic parameters during sleep [1]. A polysomnogram (PSG) uses electroencephalogram, electro-oculogram, electromyogram and electrocardiogram. In addition, pulse oximetry, airflow and respiratory effort evaluate for underlying causes of sleep disturbances. An hypnogram is derived from polysomnography. Sleep stage scoring is performed visually by an expert on epochs of 30 seconds of signals recording. The graphical representation is useful to analyse the sleep cycle and several parameters are usually computed to quantify and characterize sleep, such as the sleep efficiency (SE: time a person spends asleep / total time dedicated to sleep), sleep onset latency (SOL: time for transition from full wakefulness to sleep), REM sleep percentage (REMp), NonREM sleep percentage (NREMp), and REM latency [2]. Even though polysomnography is often used in sleep disorders studies, this technique is expensive, uncomfortable and sometimes invasive.\n",
    "\n",
    "Dreem is a company which proposes a smaller device to study sleep [3]. Dreem headband allows doing polysomnography at home thanks to specific sensors and equipments that allow a measure of electroencephalogram (EEG), pulse oximeter and accelerometer signals. The aim of Dreem is to monitor sleep as precisely as PSG, with a study at home and offering personalized recommendations to improve overall sleep quality.\n",
    "\n",
    "The purpose of the Challenge is to develop an algorithm of sleep staging able to differentiate between Wake, N1, N2, N3 and REM on windows of 30 seconds of raw data. The raw data include 5 EEG channels in frontal and occipital position, and 3 accelerometers channels (x, y and z).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5276caeb",
   "metadata": {},
   "source": [
    "# Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a470852",
   "metadata": {},
   "source": [
    "Our work is based on the method of the article \"A Comparative Study on Classification of Sleep Stage Based on EEG Signals Using Feature Selection and Classification Algorithms\" from Baha Şen & Musa Peker & Abdullah Çavuşoğlu & Fatih V. Çelebi [5] and the features from the article \"Sleep Stage Classification Using EEG Signal Analysis: A Comprehensive Survey and New Investigation\" from Khald Ali I. Aboalayon 1, Miad Faezipour 1, [4].\n",
    "\n",
    "In Addition, we applied Power Spectral Density on our data, based on the article \"Chambon, Stanislas, Mathieu N. Galtier, Pierrick J. Arnal, Gilles Wainrib, et Alexandre Gramfort. « A Deep Learning Architecture for Temporal Sleep Stage Classification Using Multivariate and Multimodal Time Series ».[6]\n",
    "\n",
    "The design of the pipeline is based on pre-processing, features extraction and selection, and classification. Features are extracted from both Train and Test data. The model is trained on Training Data from which features have been selected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bc589f",
   "metadata": {},
   "source": [
    "# Libraries and global variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75c4dba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common libraries\n",
    "from typing import Union, Tuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import math as m\n",
    "\n",
    "# file management\n",
    "import pandas\n",
    "import h5py\n",
    "\n",
    "# signal processing\n",
    "from scipy import signal, ndimage, stats\n",
    "import antropy\n",
    "import mne\n",
    "from mne.time_frequency import psd_welch\n",
    "import eeglib\n",
    "import pywt\n",
    "\n",
    "# sklearn\n",
    "import sklearn\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "\n",
    "NB_WINDOW = 15000\n",
    "NB_SAMPLES = 1500\n",
    "NB_EEG = 5\n",
    "NB_ACC = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894c588c",
   "metadata": {},
   "source": [
    "# Pre-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3328eac8",
   "metadata": {},
   "source": [
    "Each EEG channel is filtered with a 8-order butterworth band-pass filter which is commonly used in sleep-stage classification. With this filter, we divided our signals into subbands that correspond to biologically relevant frequency bands in Hz : Delta (0.5-4), Theta (4-8), Alpha (8-12), Spindle (12-16), Beta (16-35). However, those frequency bands can largely vary interindividually and this variability can affect the prediction quality. According to the Shannon criteria, the sampling frequency should be at least twice higher than the signal frequenct. Therefore, due to the sampling frequency of the data, it becomes difficult to extract Spindle and Beta waves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f887299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butterworth_filter(eeg: np.ndarray, fc: Union[float, Tuple[float]], typ: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Takes an eeg array and computes the filtered eeg using a butterworth low or band pass filter.\n",
    "    Returns the filtered eeg.\n",
    "    \"\"\"\n",
    "    sos = signal.butter(8, fc, typ, fs=50, output=\"sos\")\n",
    "    filtered = signal.sosfilt(sos, eeg)\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def eeg_bands(X: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Takes a dictionnary containing each X channel and filteres each eeg channel within each frequency band.\n",
    "    Returns a dictionnary of dictionnaries containing each eeg channel filtered within each frequency band.\n",
    "    \"\"\"\n",
    "    # creation of filtered signal dictionnaries\n",
    "    eeg_1 = {}\n",
    "    eeg_2 = {}\n",
    "    eeg_4 = {}\n",
    "    eeg_5 = {}\n",
    "    eeg_6 = {}\n",
    "\n",
    "    # gathering of those dictionnaries\n",
    "    eeg_f = {\"eeg_1\": eeg_1, \"eeg_2\": eeg_2, \"eeg_4\": eeg_4, \"eeg_5\": eeg_5, \"eeg_6\": eeg_6}\n",
    "\n",
    "    band_names = [\"Global\", \"Dela1_k_complexes\", \"Delta\", \"Theta\", \"Alpha\", \"Spindle\", \"Beta\"]\n",
    "    fc = {\n",
    "        \"Global\": 0.5,\n",
    "        \"Dela1_k_complexes\": (0.5, 2),\n",
    "        \"Delta\": (2, 4),\n",
    "        \"Theta\": (4, 8),\n",
    "        \"Alpha\": (8, 12),\n",
    "        \"Spindle\": (12, 16),\n",
    "        \"Beta\": 16,\n",
    "    }\n",
    "\n",
    "    nb_window = X[\"eeg_1\"].shape[0]\n",
    "\n",
    "    for key, value in eeg_f.items():\n",
    "        for name in band_names:\n",
    "            if name == \"Beta\" or name == \"Global\":\n",
    "                # due to the sampling frequency, this band is not going to be well extracted\n",
    "                value[name] = butterworth_filter(X[key], fc[name], \"lowpass\")\n",
    "            else:\n",
    "                value[name] = butterworth_filter(X[key], fc[name], \"bandpass\")\n",
    "    return eeg_f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16955cad",
   "metadata": {},
   "source": [
    "# Feature extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a42b9ce",
   "metadata": {},
   "source": [
    "## Power Spectral Density\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb32a50",
   "metadata": {},
   "source": [
    "First, we extracted the Power Spectral Density (PSD). The PSD of a signal describes the power present in the signal as a function of frequency. It is defined by Fourier Transform squared module divided by Spectral band width.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b2fa0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eeg_power_band(X: dict) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Takes a dictionnary containing each X channel and filters each eeg channel within each frequency band.\n",
    "    Returns a dictionnary of dictionnaries containing each eeg channel filtered within each frequency band.\n",
    "    \"\"\"\n",
    "    # specific frequency bands\n",
    "    FREQ_BANDS = {\n",
    "        \"delta\": [0.5, 4.5],\n",
    "        \"theta\": [4.5, 8.5],\n",
    "        \"alpha\": [8.5, 11.5],\n",
    "        \"sigma\": [11.5, 15.5],\n",
    "        \"beta\": [15.5, 30],\n",
    "    }\n",
    "\n",
    "    channel_i = 0\n",
    "\n",
    "    # gather all the channels in one array\n",
    "    all_eeg = np.zeros((NB_WINDOW, NB_EEG, NB_SAMPLES))\n",
    "    for key_eeg, eeg_i in X.items():\n",
    "        if key_eeg == \"eeg_1\" or key_eeg == \"eeg_2\" or key_eeg == \"eeg_4\" or key_eeg == \"eeg_5\" or key_eeg == \"eeg_6\":\n",
    "            all_eeg[:, channel_i, :] = eeg_i\n",
    "            channel_i += 1\n",
    "\n",
    "    # creating information about the EEGs\n",
    "    info = mne.create_info([\"eeg_1\", \"eeg_2\", \"eeg_4\", \"eeg_5\", \"eeg_6\"], sfreq=50, ch_types=\"eeg\")\n",
    "    # creating epochs datatype from the EEGs data\n",
    "    epochs = mne.EpochsArray(all_eeg, info)\n",
    "\n",
    "    psds, freqs = psd_welch(epochs, picks=\"eeg\", fmin=0.5, fmax=30.0)\n",
    "    # normalize the PSDs\n",
    "    psds /= np.sum(psds, axis=-1, keepdims=True)\n",
    "\n",
    "    X = []\n",
    "    # PSD classified by frequency bands and averaged on EEG channels\n",
    "    for fmin, fmax in FREQ_BANDS.values():\n",
    "        psds_band = psds[:, :, (freqs >= fmin) & (freqs < fmax)].mean(axis=-1)\n",
    "        X.append(psds_band.reshape(len(psds), -1))\n",
    "\n",
    "    return np.concatenate(X, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ad5a0f",
   "metadata": {},
   "source": [
    "## EEG features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5866662",
   "metadata": {},
   "source": [
    "EEG features are based on the review \"Sleep Stage Classification Using EEG Signal Analysis:\n",
    "A Comprehensive Survey and New Investigation\" from Khald Ali I. Aboalayon 1, Miad Faezipour 1 [4]\n",
    "\n",
    "In their work, they segmente the signal in the time domain into sub-windows to apply Maximum-Minimum Distance (MMD) which corresponds to the sum distance between highest and lowest points. They also apply EnergySis (Esis), which determines the energy and speed of the EEG.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dcdf7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmd(eeg: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Takes an eeg array and computes the Maximum-Minimum Distance (MMD).\n",
    "    Returns the sum of MMD for all sub-windows.\n",
    "    \"\"\"\n",
    "    # wave length of the window\n",
    "    lambda_ = 100\n",
    "    nb_sub_window = int(NB_SAMPLES / lambda_)\n",
    "    d = np.zeros(NB_WINDOW, nb_sub_window)\n",
    "    for sub_window_i in range(nb_sub_window):\n",
    "        # selection of the sub-window\n",
    "        current = eeg[:, lambda_ * sub_window_i : lambda_ * (sub_window_i + 1)]\n",
    "        maxi = np.max(current, axis=1)\n",
    "        maxi_ind = np.argmax(current, axis=1)\n",
    "        mini = np.min(current, axis=1)\n",
    "        mini_ind = np.argmin(current, axis=1)\n",
    "        # distance computation for sub-window\n",
    "        d[:, sub_window_i] = np.sqrt((maxi_ind - mini_ind) ** 2 + (maxi - mini) ** 2)\n",
    "    # sum of all sub-windows\n",
    "    return np.sum(d, axis=1)\n",
    "\n",
    "\n",
    "def esis(eeg: np.ndarray, w1: float, w2: float) -> float:\n",
    "    \"\"\"\n",
    "    Takes an eeg array and computes the EnergySis (Esis) metric.\n",
    "    Returns Esis.\n",
    "    \"\"\"\n",
    "    # w1 and w2 correspond to the EEG frequencies of defined subbands\n",
    "    lambda_ = 100\n",
    "    v = lambda_ * (w1 + w2) / 2\n",
    "    esis = np.sum(eeg**2, axis=1) * v\n",
    "    return esis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283a108c",
   "metadata": {},
   "source": [
    "A discrete wavelet transform (DWT) is a transform that decomposes a given signal into a number of sets, where each set is a time series of coefficients describing the time evolution of the signal in the corresponding frequency band.\n",
    "This is a transformation method developed to overcome the deficiencies of the Fourier transformation over\n",
    "non-stationary signals and this method is less sensitive towards noise and can be easily applied to non-stationary signals.\n",
    "With several level of transform, Details (D) and Approximated (A) coefficients are calculated.\n",
    "As the authors do, we focused on the D3, D4, D5 and A5 coefficients. We also selected 'db4' (Daubechies of order 4) and level = 5. The WaveletPacket allows to have better features extraction for numerous EEG data.\n",
    "\n",
    "The features to be extracted are:\n",
    "\n",
    "1. Mean of the absolute values of the coefficients in each sub-band (D3-1, D4-1, D5-1, and A5-1).\n",
    "2. Average power of the wavelet coefficients in each sub-band (D3-2, D4-2, D5-2, and A5-2).\n",
    "3. Standard deviation of the coefficients in each sub-band (D3-3, D4-3, D5-3, and A5-3).\n",
    "4. Ratio of the absolute mean values of adjacent sub-bands (D3-4, D4-4, D5-4, and A5-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "761aed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Wavelet(eeg: np.ndarray) -> list:\n",
    "    \"\"\"\n",
    "    Takes an eeg array and computes the features describe below thanks to discrete wavelet transform.\n",
    "    Returns a list of those features.\n",
    "    \"\"\"\n",
    "    # definition of the wavelets packets\n",
    "    wp = pywt.WaveletPacket(eeg, wavelet=\"db4\", mode=\"symmetric\", maxlevel=5, axis=1)\n",
    "    # coefficients of interest\n",
    "    aad = wp[\"aad\"].data  # D3\n",
    "    aaaa = wp[\"aaaa\"].data\n",
    "    aaad = wp[\"aaad\"].data  # D4\n",
    "    aaaad = wp[\"aaaad\"].data  # D5\n",
    "    aaaaa = wp[\"aaaaa\"].data  # A5\n",
    "\n",
    "    re = []\n",
    "    for i in [\"aad\", \"aaad\", \"aaaad\", \"aaaaa\"]:\n",
    "        re.append(wp[i].data)\n",
    "    # energy feature\n",
    "    wp_features = []\n",
    "    for i, x in enumerate(re):\n",
    "        wp_features.append(pow(np.linalg.norm(x, ord=None, axis=1), 2))\n",
    "    # mean values of coefficients\n",
    "    mean_value_D3_1 = np.mean(aad, axis=1)\n",
    "    mean_value_D4_1 = np.mean(aaad, axis=1)\n",
    "    mean_value_D5_1 = np.mean(aaaad, axis=1)\n",
    "    mean_value_A5_1 = np.mean(aaaaa, axis=1)\n",
    "\n",
    "    wp_features.append(mean_value_D3_1)\n",
    "    wp_features.append(mean_value_D4_1)\n",
    "    wp_features.append(mean_value_D5_1)\n",
    "    wp_features.append(mean_value_A5_1)\n",
    "\n",
    "    # standard deviation values of coefficients\n",
    "    deviation_D3_3 = np.std(aad, axis=1)\n",
    "    deviation_D4_3 = np.std(aaad, axis=1)\n",
    "    deviation_D5_3 = np.std(aaaad, axis=1)\n",
    "    deviation_A5_3 = np.std(aaaaa, axis=1)\n",
    "\n",
    "    wp_features.append(deviation_D3_3)\n",
    "    wp_features.append(deviation_D4_3)\n",
    "    wp_features.append(deviation_D5_3)\n",
    "    wp_features.append(deviation_A5_3)\n",
    "\n",
    "    # mean ratios with adjacent subbands\n",
    "    ratio_mean_D3_4 = mean_value_D3_1 / mean_value_D4_1\n",
    "    ratio_mean_D4_4 = mean_value_D4_1 / mean_value_D5_1\n",
    "    ratio_mean_D5_4 = mean_value_D5_1 / mean_value_D4_1\n",
    "    ratio_mean_A5_4 = mean_value_A5_1 / np.mean(aaaa, axis=1)\n",
    "\n",
    "    wp_features.append(ratio_mean_D3_4)\n",
    "    wp_features.append(ratio_mean_D4_4)\n",
    "    wp_features.append(ratio_mean_D5_4)\n",
    "    wp_features.append(ratio_mean_A5_4)\n",
    "\n",
    "    return wp_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58f279c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_features_eeg(eeg: np.ndarray) -> list:\n",
    "    \"\"\"\n",
    "    Takes an eeg array and computes a set of basic features.\n",
    "    Returns a list of those features.\n",
    "    \"\"\"\n",
    "    minimum_value = np.min(eeg, axis=1)\n",
    "    maximum_value = np.max(eeg, axis=1)\n",
    "    mean_value = np.mean(eeg, axis=1)\n",
    "    standard_deviation = np.std(eeg, axis=1, ddof=1)\n",
    "    variance = np.var(eeg, axis=1, ddof=1)\n",
    "    median = np.median(eeg, axis=1)\n",
    "    skewness = stats.skew(eeg, axis=1)\n",
    "    kurthosis = stats.kurtosis(eeg, axis=1)\n",
    "    SpEn = antropy.spectral_entropy(eeg, sf=50, axis=1)\n",
    "    zero_cross = antropy.num_zerocross(eeg, axis=1)\n",
    "\n",
    "    # for functions that cannot treat data by axis\n",
    "    pfd, Hjorth, hfd, lzc, ApEn, PEn = [], [], [], [], [], []\n",
    "    for window_i in range(NB_WINDOW):\n",
    "        pfd.append(eeglib.features.PFD(eeg[window_i, :]))\n",
    "        Hjorth.append(eeglib.features.hjorthComplexity(eeg[window_i, :]))\n",
    "        hfd.append(eeglib.features.HFD(eeg[window_i, :]))\n",
    "        lzc.append(eeglib.features.LZC(eeg[window_i, :]))\n",
    "        ApEn.append(antropy.sample_entropy(eeg[window_i, :]))\n",
    "        PEn.append(antropy.perm_entropy(eeg[window_i, :]))\n",
    "\n",
    "    feature_list = [\n",
    "        minimum_value,\n",
    "        maximum_value,\n",
    "        mean_value,\n",
    "        standard_deviation,\n",
    "        variance,\n",
    "        median,\n",
    "        skewness,\n",
    "        kurthosis,\n",
    "        pfd,\n",
    "        SpEn,\n",
    "        ApEn,\n",
    "        PEn,\n",
    "        Hjorth,\n",
    "        zero_cross,\n",
    "        hfd,\n",
    "        lzc,\n",
    "    ]\n",
    "\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eef694dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eeg_features(eeg_f: dict) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Takes the dictionnary of filtered eeg for each band and computes features for each band and each channel.\n",
    "    Returns the mean of those features over all channels.\n",
    "    \"\"\"\n",
    "    band_names = [\"Dela1_k_complexes\", \"Delta\", \"Theta\", \"Alpha\", \"Spindle\", \"Beta1\", \"Beta2\"]\n",
    "    fc = {\n",
    "        \"Global\": 0.5,\n",
    "        \"Dela1_k_complexes\": (0.5, 2),\n",
    "        \"Delta\": (2, 4),\n",
    "        \"Theta\": (4, 8),\n",
    "        \"Alpha\": (8, 12),\n",
    "        \"Spindle\": (12, 16),\n",
    "        \"Beta\": (16, 24),\n",
    "    }\n",
    "\n",
    "    nb_features = 16 * 6 + 2 * 6 + 16 * 6\n",
    "    X_features = np.zeros((NB_WINDOW, NB_EEG, nb_features))\n",
    "\n",
    "    channel_i = 0\n",
    "    for key_eeg, eeg_i in eeg_f.items():\n",
    "        print(key_eeg)\n",
    "        effective_band_j = 0\n",
    "        for key_band, band_i in eeg_i.items():\n",
    "            if key_band != \"Global\":\n",
    "                features = basic_features_eeg(band_i)\n",
    "                MMD = mmd(band_i)\n",
    "                features.append(MMD)\n",
    "                esis_ = esis(band_i, fc[key_band][0], fc[key_band][1])\n",
    "                features.append(esis_)\n",
    "                wavelet_ = Wavelet(band_i)\n",
    "                for wv in wavelet_:\n",
    "                    features.append(wv)\n",
    "                features = np.array(features).T\n",
    "\n",
    "                X_features[:, channel_i, 34 * effective_band_j : 34 * (effective_band_j + 1)] = features\n",
    "\n",
    "                effective_band_j += 1\n",
    "        channel_i += 1\n",
    "    X_features = np.mean(X_features, axis=1)\n",
    "    return X_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07040503",
   "metadata": {},
   "source": [
    "## Accelerometer features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc2b69f",
   "metadata": {},
   "source": [
    "Accelerometers are included in the Dreem headband. They correspond to 3 accelerometer channels (x, y and z). Accelerometers monitor movement, and there is little difference in movement between sleep stages.\n",
    "\n",
    "x - Accelerometer along x axis sampled at 10 Hz, 300 values\n",
    "y - Accelerometer along y axis sampled at 10 Hz, 300 values\n",
    "z - Accelerometer along z axis sampled at 10 Hz, 300 values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab1e9389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_features_acc(acc: np.ndarray) -> list:\n",
    "    \"\"\"\n",
    "    Takes an accelerometer array and computes a set of basic features.\n",
    "    Returns a list of those features.\n",
    "    \"\"\"\n",
    "    minimum_value = np.min(acc, axis=1)\n",
    "    maximum_value = np.max(acc, axis=1)\n",
    "    mean_value = np.mean(acc, axis=1)\n",
    "    standard_deviation = np.std(acc, ddof=1, axis=1)\n",
    "    median_absolute_deviation = stats.median_abs_deviation(acc, axis=1)\n",
    "    variance = np.var(acc, ddof=1, axis=1)\n",
    "    median = np.median(acc, axis=1)\n",
    "    skewness = stats.skew(acc, axis=1)\n",
    "    kurthosis = stats.kurtosis(acc, axis=1)\n",
    "\n",
    "    zero_cross = antropy.num_zerocross(acc, axis=1)\n",
    "    SpEn = antropy.spectral_entropy(acc, sf=50, axis=1)\n",
    "\n",
    "    feature_list = [\n",
    "        minimum_value,\n",
    "        maximum_value,\n",
    "        mean_value,\n",
    "        standard_deviation,\n",
    "        median_absolute_deviation,\n",
    "        variance,\n",
    "        median,\n",
    "        skewness,\n",
    "        kurthosis,\n",
    "        zero_cross,\n",
    "        SpEn,\n",
    "    ]\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb41a620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_features(X: dict) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Takes the dictionnary of X channels and computes features for accelerometer channels.\n",
    "    Returns the mean of those features over all accelerometer channels.\n",
    "    \"\"\"\n",
    "    nb_features = 11\n",
    "    X_features = np.zeros((NB_WINDOW, NB_ACC, nb_features))\n",
    "\n",
    "    keys = [\"x\", \"y\", \"z\"]\n",
    "    for key_acc, channel_i in enumerate(keys):\n",
    "        features = basic_features_acc(X[key_acc])\n",
    "        features = np.array(features).T\n",
    "\n",
    "        X_features[:, channel_i, :] = features\n",
    "    X_features = np.mean(X_features, axis=1)\n",
    "    return X_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf77b592",
   "metadata": {},
   "source": [
    "## Normalizing and gathering features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfe091eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X_features):\n",
    "    \"\"\"\n",
    "    Takes the dictionnary of X channels and normalizes by feature.\n",
    "    Returns the normalized feature array.\n",
    "    \"\"\"\n",
    "    # remove non-values and infinite values\n",
    "    X_features = np.where(np.isnan(X_features), 0, X_features)\n",
    "    X_features = np.where(X_features == np.inf, 0, X_features)\n",
    "    # normalizing X\n",
    "    return (X_features - np.mean(X_features, axis=0, keepdims=True)) / np.std(X_features, axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b7d1ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_transformer(X):\n",
    "    \"\"\"\n",
    "    Takes the dictionnary of X channels and computes global features for accelerometer and eeg channels.\n",
    "    Returns those features in an array.\n",
    "    \"\"\"\n",
    "    print(\"Getting frequency bands...\")\n",
    "    eeg_f = eeg_bands(X)\n",
    "\n",
    "    print(\"Getting Power Spectral Density...\")\n",
    "    X_mne = eeg_power_band(X)\n",
    "\n",
    "    print(\"Getting eeg features...\")\n",
    "    X_eeg_features = eeg_features(eeg_f)\n",
    "\n",
    "    print(\"Getting accelerometers features...\")\n",
    "    X_acc_features = acc_features(X)\n",
    "\n",
    "    X_features = np.concatenate((X_eeg_features, X_acc_features), axis=1)\n",
    "    X_features = normalize(X_features)\n",
    "\n",
    "    X_global_features = np.concatenate((X_mne, X_features), axis=1)\n",
    "    return X_global_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57fa0d6",
   "metadata": {},
   "source": [
    "# Feature selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bab5a44",
   "metadata": {},
   "source": [
    "We obtained a large number of features. We now want to reduce them to obtain a more accurate model of the data, and thus obtain a better performance.\n",
    "\n",
    "We used a recursive feature elimination method by cross-validation loop. The algorithm evaluates at each step the set of features and finds one or more least significant features by cross-validation loop.\n",
    "Then it starts again until it estimates that all the remaining features are significant, which makes the classification more efficient and increases the performance of the model.\n",
    "As this algorithm can be expensive, the executing time has been reduced by selecting the number of features to be eliminated at each iteration and using parallel processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd287bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X: np.ndarray, y: np.ndarray, best_estimator: np.ndarray):\n",
    "    \"\"\"\n",
    "    Performs recursive feature elimination that improves the model.\n",
    "    Returns the resulting feature selector.\n",
    "    \"\"\"\n",
    "    estimator = best_estimator\n",
    "\n",
    "    # feature selection with cross validation\n",
    "    selector = RFECV(estimator, n_jobs=-1, scoring=\"f1_macro\", step=7)\n",
    "    selector = selector.fit(X, y)\n",
    "\n",
    "    # selector contains information about the number of features selected\n",
    "    # the ranking and if we should support them or not\n",
    "    return selector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e12fad1",
   "metadata": {},
   "source": [
    "# Classification procedure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b08b74",
   "metadata": {},
   "source": [
    "Random Forest is an algorithm that was first proposed by Leo Breiman in 2001. It is based on the generation of prediction trees taking into account a subpart of the data.\n",
    "\n",
    "During training, the algorithm randomly selects observation points (epochs) as well as features and builds a tree for each random sub-draw it has made.\n",
    "Each tree is trained on its data providing a partial model.\n",
    "\n",
    "During the test, each subtree in the forest predicts the class to which the observation belongs. The majority class wins and this class is assigned to the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1476382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_params(train_features: np.ndarray, train_labels: np.ndarray):\n",
    "    \"\"\"\n",
    "    Performs a random search to find the Random Forest Classifier (with hyper-parameters) that fits best the data.\n",
    "    Returns the result of this search.\n",
    "    \"\"\"\n",
    "    # number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start=100, stop=2000, num=50)]\n",
    "    # number of features to consider at every split\n",
    "    max_features = [\"auto\", \"sqrt\"]\n",
    "    # maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 100, num=10)]\n",
    "    # minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    class_weight = [\"balanced\", \"balanced_subsample\"]\n",
    "    # create the random grid\n",
    "    random_grid = {\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"max_features\": max_features,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"min_samples_split\": min_samples_split,\n",
    "        \"min_samples_leaf\": min_samples_leaf,\n",
    "        \"bootstrap\": bootstrap,\n",
    "        \"class_weight\": class_weight,\n",
    "    }\n",
    "    # use the random grid to search for best hyperparameters\n",
    "    # first create the base model to tune\n",
    "    rf = RandomForestClassifier()\n",
    "    # random search of parameters, using 3 fold cross validation,\n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    rf_random = RandomizedSearchCV(\n",
    "        estimator=rf, param_distributions=random_grid, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    # fit the random search model\n",
    "    rf_random.fit(train_features, train_labels)\n",
    "\n",
    "    return rf_random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fe7a8b",
   "metadata": {},
   "source": [
    "# Main function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4751be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # open files\n",
    "    with open(\"data/y_train.csv\", \"r\") as file_ytrain:\n",
    "        ytrain = pandas.read_csv(file_ytrain)\n",
    "        Xtrain = h5py.File(\"data/X_train.h5\", \"r\")\n",
    "        Xtest = h5py.File(\"data/X_test.h5\", \"r\")\n",
    "\n",
    "        # 3 accelerometers\n",
    "        x = Xtrain[\"x\"]\n",
    "        y = Xtrain[\"y\"]\n",
    "        z = Xtrain[\"z\"]\n",
    "\n",
    "        # index\n",
    "        index = Xtrain[\"index\"]\n",
    "        ind = [1, 2, 4, 5, 6]\n",
    "\n",
    "        ytrain = ytrain.iloc[:, 1]\n",
    "\n",
    "        print(\"Perfoming feature extraction for the training set...\")\n",
    "        # get features\n",
    "        X_features_train = function_transformer(Xtrain)\n",
    "\n",
    "        print(\"Performing feature extraction for the testing set...\")\n",
    "        X_features_test = function_transformer(Xtest)\n",
    "\n",
    "        # find roughly the best parameters for the model to use it to select features\n",
    "        best = best_params(X_features_train, ytrain)\n",
    "\n",
    "        # find best features for the model\n",
    "        selected = select_features(X_features_train, ytrain, best.best_estimator_)\n",
    "\n",
    "        # selected.support_ is a list of booleans that tells which feature we should keep\n",
    "        X_features_train_reduced = np.delete(X_features_train, np.where(selected.support_ == False), axis=1)\n",
    "        X_features_test_reduced = np.delete(X_features_test, np.where(selected.support_ == False), axis=1)\n",
    "\n",
    "        # find roughly the best parameters for the reduced model\n",
    "        best = best_params(X_features_train_reduced, ytrain)\n",
    "        clf = best.best_estimator_\n",
    "\n",
    "        scores = clf.cross_val_score(X_features_train_reduced, ytrain)\n",
    "        print(f\"The average score with cross validation was {np.mean(scores)}\")\n",
    "\n",
    "        clf.fit(X_features_train_reduced, ytrain)\n",
    "\n",
    "        y_pred = clf.predict(X_features_test_reduced)\n",
    "\n",
    "        # write the result in a CSV file\n",
    "        C = {\"index\": list(range(NB_WINDOW, NB_WINDOW + 6000)), \"sleep_stage\": y_pred}\n",
    "        data = pandas.DataFrame(C)\n",
    "        data.to_csv(\"submission_v3.csv\", index=None, header=True, encoding=\"utf-8\", sep=\",\")\n",
    "        print(\"Output written.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4999d78",
   "metadata": {},
   "source": [
    "# Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecc0227",
   "metadata": {},
   "source": [
    "In the context of Dreem headbands, we developped an algorithm of sleep staging able to differentiate between Wake, N1, N2, N3 and REM on windows of 30 seconds of raw data, with 5 EEG channels in frontal and occipital position and 3 accelerometers channels (x, y and z).\n",
    "We extracted features based on different articles. We used the RandomForest Classifier and recursive feature elimination with cross validation to eliminate unrelevant features.\n",
    "\n",
    "This algorithm allows to classify sleep stages according to accelerometer and eeg recordings.\n",
    "Our F1-Score is 0.62333.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b799586c",
   "metadata": {},
   "source": [
    "# Bibliography\n",
    "\n",
    "[1] Rundo, J.V., and Downey, R. (2019). Polysomnography. Handb Clin Neurol 160, 381–392.\n",
    "\n",
    "[2] Domingues, A., Paiva, T., and Sanches, J.M. (2014). Hypnogram and sleep parameter computation from activity and cardiovascular data. IEEE Trans Biomed Eng 61, 1711–1719.\n",
    "\n",
    "[3] Arnal, P.J., Thorey, V., Debellemaniere, E., Ballard, M.E., Bou Hernandez, A., Guillot, A., Jourde, H., Harris, M., Guillard, M., Van Beers, P., et al. (2020). The Dreem Headband compared to polysomnography for electroencephalographic signal acquisition and sleep staging. Sleep 43, zsaa097.\n",
    "\n",
    "[4] Aboalayon, Khald Ali I., Miad Faezipour, Wafaa S. Almuhammadi, et Saeid Moslehpour. « Sleep Stage Classification Using EEG Signal Analysis: A Comprehensive Survey and New Investigation ». Entropy 18, nᵒ 9 (septembre 2016): 272. https://doi.org/10.3390/e18090272.\n",
    "\n",
    "[5] Şen, Baha, Musa Peker, Abdullah Çavuşoğlu, et Fatih V. Çelebi. « A Comparative Study on Classification of Sleep Stage Based on EEG Signals Using Feature Selection and Classification Algorithms ». Journal of Medical Systems 38, nᵒ 3 (mars 2014): 18. https://doi.org/10.1007/s10916-014-0018-0.\n",
    "\n",
    "[6] Chambon, Stanislas, Mathieu N. Galtier, Pierrick J. Arnal, Gilles Wainrib, et Alexandre Gramfort. « A Deep Learning Architecture for Temporal Sleep Stage Classification Using Multivariate and Multimodal Time Series ». IEEE Transactions on Neural Systems and Rehabilitation Engineering 26, nᵒ 4 (avril 2018): 758‑69. https://doi.org/10.1109/TNSRE.2018.2813138.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('little_RNN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "613bf1c6ce9bd4231734563940869544030b8be12533da5053e820914d9fbcc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
